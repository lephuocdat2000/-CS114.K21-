{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMuoif0TndTwAZ28WQ1aWwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lephuocdat2000/-CS114.K21-/blob/master/sacarsmdetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QIbiqjOTba0",
        "colab_type": "text"
      },
      "source": [
        "***Mô tả bài toán***: Đây là bài toán nhằm dự đoán xem một bài báo có phải là châm biếm hay không dựa vào tiêu đề của nó."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRwy_iOXU5is",
        "colab_type": "text"
      },
      "source": [
        "***Cách thức thu thập dataset:*** \n",
        " - Thu thập các headline và đường link của dataset về châm biếm từ trang báo https://www.theonion.com/ , đây là trang chỉ viết các bài báo châm biếm.\n",
        " - Thu thập các headline và đường link của dataset không phải châm biếm từ trang báo https://www.huffpost.com/, đây là trang chỉ viết các bài báo chính thống. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAIgmuv8KEP2",
        "colab_type": "text"
      },
      "source": [
        "Đầu tiên tiến hành liên kết googledrive với googlecolab để lấy dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbzd7LQTH-K-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "8e3477f7-8db6-439f-e466-30d659500ff0"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')  #liên kết nội dung của googledrive vào googlecolab tại thư mục có tên drive trên googlecolab"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGypvXBZLNe6",
        "colab_type": "text"
      },
      "source": [
        "Tiến hành đọc dữ liệu bằng thư viện pandas và đường liên kết của file dữ liệu có sẵn trong thư mục theo đường link drive/My Drive/SarcasmDetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zYBFbJAVW3N",
        "colab_type": "text"
      },
      "source": [
        "Tiến hành đọc dữ liệu gốc của bài toán từ 2 file .json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGBtycu5JVns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "986dfb27-61f0-475f-8e6b-233b2d60be1c"
      },
      "source": [
        "import pandas as pd\n",
        "data1=pd.read_json('/content/drive/My Drive/SarcasmDetection/Sarcasm_Headlines_Dataset.json',lines=True) \n",
        "#lines=True ở đây có nghĩa là đọc dữ liệu theo từng dòng\n",
        "data1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26704</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/american-...</td>\n",
              "      <td>american politics in moral free-fall</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26705</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/americas-...</td>\n",
              "      <td>america's best 20 hikes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26706</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/reparatio...</td>\n",
              "      <td>reparations and obama</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26707</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/israeli-b...</td>\n",
              "      <td>israeli ban targeting boycott supporters raise...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26708</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/gourmet-g...</td>\n",
              "      <td>gourmet gifts for the foodie 2014</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26709 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            article_link  ... is_sarcastic\n",
              "0      https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1      https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2      https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3      https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4      https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "...                                                  ...  ...          ...\n",
              "26704  https://www.huffingtonpost.com/entry/american-...  ...            0\n",
              "26705  https://www.huffingtonpost.com/entry/americas-...  ...            0\n",
              "26706  https://www.huffingtonpost.com/entry/reparatio...  ...            0\n",
              "26707  https://www.huffingtonpost.com/entry/israeli-b...  ...            0\n",
              "26708  https://www.huffingtonpost.com/entry/gourmet-g...  ...            0\n",
              "\n",
              "[26709 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jq6qXRbSn1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2=pd.read_json('/content/drive/My Drive/SarcasmDetection/Sarcasm_Headlines_Dataset_v2.json',lines=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ESIB-7iGmI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "b979eb92-bea2-406c-8ab6-7994245a133a"
      },
      "source": [
        "data2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28614</th>\n",
              "      <td>1</td>\n",
              "      <td>jews to celebrate rosh hashasha or something</td>\n",
              "      <td>https://www.theonion.com/jews-to-celebrate-ros...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28615</th>\n",
              "      <td>1</td>\n",
              "      <td>internal affairs investigator disappointed con...</td>\n",
              "      <td>https://local.theonion.com/internal-affairs-in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28616</th>\n",
              "      <td>0</td>\n",
              "      <td>the most beautiful acceptance speech this week...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/andrew-ah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28617</th>\n",
              "      <td>1</td>\n",
              "      <td>mars probe destroyed by orbiting spielberg-gat...</td>\n",
              "      <td>https://www.theonion.com/mars-probe-destroyed-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28618</th>\n",
              "      <td>1</td>\n",
              "      <td>dad clarifies this not a food stop</td>\n",
              "      <td>https://www.theonion.com/dad-clarifies-this-no...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28619 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       is_sarcastic  ...                                       article_link\n",
              "0                 1  ...  https://www.theonion.com/thirtysomething-scien...\n",
              "1                 0  ...  https://www.huffingtonpost.com/entry/donna-edw...\n",
              "2                 0  ...  https://www.huffingtonpost.com/entry/eat-your-...\n",
              "3                 1  ...  https://local.theonion.com/inclement-weather-p...\n",
              "4                 1  ...  https://www.theonion.com/mother-comes-pretty-c...\n",
              "...             ...  ...                                                ...\n",
              "28614             1  ...  https://www.theonion.com/jews-to-celebrate-ros...\n",
              "28615             1  ...  https://local.theonion.com/internal-affairs-in...\n",
              "28616             0  ...  https://www.huffingtonpost.com/entry/andrew-ah...\n",
              "28617             1  ...  https://www.theonion.com/mars-probe-destroyed-...\n",
              "28618             1  ...  https://www.theonion.com/dad-clarifies-this-no...\n",
              "\n",
              "[28619 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj6KNhprObQn",
        "colab_type": "text"
      },
      "source": [
        "Tiến hành ghép 2 bộ dữ liệu chúng ta vừa đọc thành một bộ dữ liệu tổng quát bằng câu lệnh pd.concat(câu lệnh ghép các đối tượng pandas với nhau theo trục)\n",
        "ở đây cố định là trục 0 hay trục dọc nên k cần thay đổi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuGd-ftQZhfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.concat([data1,data2],ignore_index=True)   "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEe2qMQOO3Cj",
        "colab_type": "text"
      },
      "source": [
        "ignore_index=True nghĩa là bộ data2 sẽ được gộp vào bộ data1 và sẽ nhận các giá trị index mới, không phải từ  1 -> 28618  mà bắt đầu từ 26709 -> 55327"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrn5MjwIPQda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "6f0e5424-8f0a-437e-8cff-3cc1a366bab1"
      },
      "source": [
        "data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55323</th>\n",
              "      <td>https://www.theonion.com/jews-to-celebrate-ros...</td>\n",
              "      <td>jews to celebrate rosh hashasha or something</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55324</th>\n",
              "      <td>https://local.theonion.com/internal-affairs-in...</td>\n",
              "      <td>internal affairs investigator disappointed con...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55325</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/andrew-ah...</td>\n",
              "      <td>the most beautiful acceptance speech this week...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55326</th>\n",
              "      <td>https://www.theonion.com/mars-probe-destroyed-...</td>\n",
              "      <td>mars probe destroyed by orbiting spielberg-gat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55327</th>\n",
              "      <td>https://www.theonion.com/dad-clarifies-this-no...</td>\n",
              "      <td>dad clarifies this not a food stop</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55328 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            article_link  ... is_sarcastic\n",
              "0      https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1      https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2      https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3      https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4      https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "...                                                  ...  ...          ...\n",
              "55323  https://www.theonion.com/jews-to-celebrate-ros...  ...            1\n",
              "55324  https://local.theonion.com/internal-affairs-in...  ...            1\n",
              "55325  https://www.huffingtonpost.com/entry/andrew-ah...  ...            0\n",
              "55326  https://www.theonion.com/mars-probe-destroyed-...  ...            1\n",
              "55327  https://www.theonion.com/dad-clarifies-this-no...  ...            1\n",
              "\n",
              "[55328 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHqkDvFNYhDG",
        "colab_type": "text"
      },
      "source": [
        "Bộ dữ liệu khá lớn, có 3 features: + article_link (đường dẫn)\n",
        "                                  + headline ( tiêu đề bài báo)\n",
        "                                  + is_sarcastic (nếu bằng 1 thì bài báo đó là sarcasm, bằng 0 thì ngược lại).\n",
        "Tuy nhiên đối với bài toán này ta chỉ sử dụng headline và is_sarcastic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVxkfDt3zZhX",
        "colab_type": "text"
      },
      "source": [
        "Tiến hành đọc bộ dữ liệu mới tự thu thập được lưu trên ggdrive\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E04Cla52WM-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "9060579b-5747-483d-eb25-22bdd7964be2"
      },
      "source": [
        "collected_data=pd.read_excel('/content/drive/My Drive/SarcasmDetection/newdataset.xlsx')\n",
        "collected_data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Michelle Obama Shares Sweet Family Throwback P...</td>\n",
              "      <td>https://www.huffpost.com/entry/michelle-obama-...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Walk Of Shame': Deflated Trump's Lonely Helic...</td>\n",
              "      <td>https://www.huffpost.com/entry/donald-trump-he...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>John Bolton Won’t Vote For Trump, Hopes He Wil...</td>\n",
              "      <td>https://www.huffpost.com/entry/john-bolton-vot...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Noose Found In Garage Used By NASCAR’s Bubba W...</td>\n",
              "      <td>https://www.huffpost.com/entry/noose-nascar-bu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tom Petty's Family Demands Trump Stop Using 'I...</td>\n",
              "      <td>https://www.huffpost.com/entry/tom-petty-donal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2031</th>\n",
              "      <td>Department Of Evil: ‘All Of You Must Die’</td>\n",
              "      <td>https://www.theonion.com/department-of-evil-al...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2032</th>\n",
              "      <td>Giannis Antetokounmpo To Take Off Next 3 Seaso...</td>\n",
              "      <td>https://sports.theonion.com/giannis-antetokoun...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2033</th>\n",
              "      <td>Bloomberg Campaign Raises Visibility By Pumpin...</td>\n",
              "      <td>https://politics.theonion.com/bloomberg-campai...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2034</th>\n",
              "      <td>Website Offers Porn To Passengers Trapped On Q...</td>\n",
              "      <td>https://www.theonion.com/website-offers-porn-t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2035</th>\n",
              "      <td>Poll Finds Bloomberg Trailing Among Young Blac...</td>\n",
              "      <td>https://politics.theonion.com/poll-finds-bloom...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2036 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               headline  ... is_sarcastic\n",
              "0     Michelle Obama Shares Sweet Family Throwback P...  ...            0\n",
              "1     'Walk Of Shame': Deflated Trump's Lonely Helic...  ...            0\n",
              "2     John Bolton Won’t Vote For Trump, Hopes He Wil...  ...            0\n",
              "3     Noose Found In Garage Used By NASCAR’s Bubba W...  ...            0\n",
              "4     Tom Petty's Family Demands Trump Stop Using 'I...  ...            0\n",
              "...                                                 ...  ...          ...\n",
              "2031          Department Of Evil: ‘All Of You Must Die’  ...            1\n",
              "2032  Giannis Antetokounmpo To Take Off Next 3 Seaso...  ...            1\n",
              "2033  Bloomberg Campaign Raises Visibility By Pumpin...  ...            1\n",
              "2034  Website Offers Porn To Passengers Trapped On Q...  ...            1\n",
              "2035  Poll Finds Bloomberg Trailing Among Young Blac...  ...            1\n",
              "\n",
              "[2036 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWbySmsZZYiG",
        "colab_type": "text"
      },
      "source": [
        "Bộ dữ liệu mới gồm 2036 bài báo trong đó gồm 1026 bài là nonsarcasm và 1010 bài là sarcasm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juw7kqM6Zoal",
        "colab_type": "text"
      },
      "source": [
        "**Feature Engineering**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElqhotBrg3o7",
        "colab_type": "text"
      },
      "source": [
        "Kiểm tra xem có bao nhiêu kí tự số trong tập headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73youBUhbFB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "35777d28-335c-4ba1-b2b4-6017223bf6be"
      },
      "source": [
        "numbers=0\n",
        "c=''\n",
        "for x in data['headline']:\n",
        "   for c in x:\n",
        "      if (c.isdigit()==True): numbers+=1\n",
        "numbers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhfV5jLkhrlb",
        "colab_type": "text"
      },
      "source": [
        "Ta thấy rằng số kí tự số rất lớn tuy nhiên đối với yêu cầu của bài toán này thì các kí tự số không phản ánh được vấn đề bài toán mà thậm chí còn gây nhiễu, sai lệch trong quá trình training => Ta tiến hành loại bỏ kí tự số"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHeIU2t6ieKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=data['headline'].str.replace('\\d+', '')\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHJvaGenkQ85",
        "colab_type": "text"
      },
      "source": [
        " \\d+: chuỗi kí tự có một hoặc nhiều chữ số, câu lệnh ở phía trên là để thay thế toàn bộ kí tự chữ số thành kí tự trống \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxXIvPDhqs3I",
        "colab_type": "text"
      },
      "source": [
        "Tách bộ dữ liệu thành 2 phần training set và test set với tỉ lệ 80% và 20% => Tránh overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pbLMjA3Ztm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "y=data['is_sarcastic']\n",
        "X_train,X_validation,y_train,y_validation = train_test_split(X,y,test_size=0.2,random_state=1,) "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZIvGXwMkboQ",
        "colab_type": "text"
      },
      "source": [
        "random_state=1 => lựa chọn một cách ngẫu nhiên "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwJlEeQHtUpx",
        "colab_type": "text"
      },
      "source": [
        "Ta tiến hành xây dựng Bag of Words sau đó chuyển đổi các headlines về dạng ma trận với hàm CountVectorizer từ thư viện sklearn, tiếp đến dùng hàm TfidfTransformer để đánh giá lại về giá trị các từ bởi vì có những từ tuy xuất hiện nhiều lần nhưng nó lại thực sự không quan trọng (the, and, is,of,that,...)=> giúp model đạt kết quả chính xác hơn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UT07zKMvxcJ",
        "colab_type": "text"
      },
      "source": [
        "VD để hiểu rõ hơn về 2 hàm CountVectorizer() và TfidfTransformer\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umoGnDAX6VcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "fea72efa-4387-4289-9787-1d7a367b1c62"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "sentence=['This is the first document.',\n",
        "          'This is the second second document.',\n",
        "          'And the third one.',\n",
        "          'Is this the first document?',]\n",
        "vectorizer = CountVectorizer()\n",
        "y = vectorizer.fit_transform(sentence)\n",
        "print(\"Các từ trong đoạn văn:\")\n",
        "print(vectorizer.get_feature_names())\n",
        "print(\"Ma trận hóa đoạn văn:\")\n",
        "print(y.toarray())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Các từ trong đoạn văn:\n",
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "Ma trận hóa đoạn văn:\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 1 0 1 0 2 1 0 1]\n",
            " [1 0 0 0 1 0 1 1 0]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ7QWurr2t7X",
        "colab_type": "text"
      },
      "source": [
        "Cách thức hàm CountVectorizer ma trận hóa đoạn văn bản ví dụ ở trên:\n",
        "    \n",
        "   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy6RxyQc7ogT",
        "colab_type": "text"
      },
      "source": [
        "- Đầu tiên liệt kê các loại từ có trong văn bản ( ở ví dụ trên là 9 loại từ ) hay tạo mảng gồm các loại từ, ở đây giả sử gọi là mảng k."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrbJRK5j7w9m",
        "colab_type": "text"
      },
      "source": [
        " - Tiến hành ma trận hóa văn bản thành ma trận 9 cột 4 hàng (văn bản gồm 4 dòng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGYC5ydO70Y9",
        "colab_type": "text"
      },
      "source": [
        " Ví dụ về cách chuyển hàng đầu tiên: Xét các từ trong mảng k từ đầu mảng đến cuối mảng, bắt đầu với từ 'and' thì trong câu đầu tiên xuất hiện 0 lần => X[0][0]=0, từ 'document' xuất hiện 1 lần X[0][1]=1, từ 'first' xuất hiện 1 lần => X[0][2]=1,'is' xuất hiện 1 lần => X[0][3]=1, 'one' xh 0 lần => x[0][4] = 0, 'second' xuất hiện 0 lần => x[0][5]=0, 'the' xuất hiện 1 lần => x[0][6]=1,'third' xuất hiện 0 lần => x[0][7]=0, 'this' xuất hiện 1 lần => x[0][8]=1\n",
        "Vậy ta được ma trận chuyển hóa với hàng đầu tiên là: 0 1 1 1 0 0 1 0 1 \n",
        "Các hàng còn lại ta có thể làm tương tự để được kết quả như trên"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-S0yfqS2RMH",
        "colab_type": "text"
      },
      "source": [
        "Bằng việc chuyển đổi như trên thì ta được một ma trận số hóa của văn bản tuy nhiên như vậy thì những từ không có nhiều ý nghĩa như (the,and,is,..) lại có cùng mức độ quan trọng so với những từ như (document,..) => điều này có thể gây sai lệch cho model trong quá trình training nên ta phải đánh giá lại giá trị của các từ bằng TfidfTransformer()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmWz3Sti2PCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "680b2c28-7243-4599-f6fb-3ac0d4217c19"
      },
      "source": [
        "transformer = TfidfTransformer()\n",
        "print(y.toarray())\n",
        "tfidf = transformer.fit_transform(y).toarray()\n",
        "print(tfidf)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 1 0 1 0 2 1 0 1]\n",
            " [1 0 0 0 1 0 1 1 0]\n",
            " [0 1 1 1 0 0 1 0 1]]\n",
            "[[0.         0.43877674 0.54197657 0.43877674 0.         0.\n",
            "  0.35872874 0.         0.43877674]\n",
            " [0.         0.27230147 0.         0.27230147 0.         0.85322574\n",
            "  0.22262429 0.         0.27230147]\n",
            " [0.55280532 0.         0.         0.         0.55280532 0.\n",
            "  0.28847675 0.55280532 0.        ]\n",
            " [0.         0.43877674 0.54197657 0.43877674 0.         0.\n",
            "  0.35872874 0.         0.43877674]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuUKLIBWFk4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iPWs4inDKoe",
        "colab_type": "text"
      },
      "source": [
        "Giải thích về cách tính Tfidf ở đây:\n",
        "  \n",
        "  \n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzqCIPf1MAXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS0QBJsBEuD8",
        "colab_type": "text"
      },
      "source": [
        "   * Tfidf = Tf * idf,với:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wcOie1GLz2G",
        "colab_type": "text"
      },
      "source": [
        "**-** Tf: tần số xuất hiện của một từ trong văn bản đó = Số lần xuất hiện của từ nhất định / Số lần xuất hiện nhiều nhất của một từ bất kỳ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFSbHvtoErqo",
        "colab_type": "text"
      },
      "source": [
        " **-**idf: nghịch đảo tần số của văn bản chứa từ nhất định = log(Tổng số văn bản / số văn bản chứa từ đó+1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hbedsnEF4vw",
        "colab_type": "text"
      },
      "source": [
        "Ta thấy những từ không quan trọng (the,and,it,is,...) thường xuất hiện nhiều trong các văn bản cho nên theo công thức trên ta thấy số văn bản chứa từ đó càng nhiều thì idf càng thấp => tfidf càng thấp => tầm quan trọng của từ đó thấp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WycokBlBLFo1",
        "colab_type": "text"
      },
      "source": [
        "**Qua ví dụ trên ta có thể hiểu rõ hơn về Ma trận hóa văn bản và đánh giá lại mức độ quan trọng của các từ. Vậy ta tiến hành tương tự với data gốc đã cho.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHlpnAKmGn3-",
        "colab_type": "text"
      },
      "source": [
        "***Xây dựng model***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_aaSqN7HaIr",
        "colab_type": "text"
      },
      "source": [
        "Thay vì tự thực hiện tuần tực các bước biến đổi CountVectorizer(),TfidfTransformer() và fit model thì ta có thể xây dựng pipeline để liên kết 3 bước lại với nhau cho máy tự thức hiện một cách nhanh gọn và thuận lợi hơn trong việc tinh chỉnh tham số."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s_30ozPMXq6",
        "colab_type": "text"
      },
      "source": [
        "Vì đây là bài toán phân lớp nên ta sẽ chọn những thuật toán phân lớp. Thuật toán lựa chọn để train model ở đây là Multinomial Naive Bayes vì đây là thuật toán được sử dụng nhiều trong text classification mà các feature vectors được tính bằng Bag of words, nó thực hiện nhanh, hàm dự đoán xác suất đơn giản nên dễ giải thích, tinh chỉnh tham số"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OozebqhIa2eH",
        "colab_type": "text"
      },
      "source": [
        "NAIVE BAYES\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzhQUxVJa8pY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "56a7f260-8b9f-4ca5-cbd4-f59609fca728"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB # thuật toán MultinomialNaiveBayes\n",
        "from sklearn.pipeline import Pipeline  #import pipeline => xây dựng pipeline cho model\n",
        "from sklearn.metrics import accuracy_score #đánh giá hiệu suất model\n",
        "target_name=['is_sacarsm','non_sacarsm']\n",
        "#xây dựng pipeline theo tuần tự các bước như đã nêu ở trên\n",
        "model=Pipeline([('vect',CountVectorizer()),     #stop_word='english' => loại bỏ các từ thuộc stop_word trong tiếng Anh ( the,on,a,an,...) \n",
        "               ('tfidf',TfidfTransformer(False)),\n",
        "               ('clf',MultinomialNB()),\n",
        "])\n",
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm=False, smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OfRsApWnkRh",
        "colab_type": "text"
      },
      "source": [
        "Quá trình học của model: model sẽ tính toán xác xuất có điều kiện của mỗi word xuất hiện trên nhãn của nó (is_sarcasm or sarcasm) với công thức: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCPRH6UWpM4P",
        "colab_type": "text"
      },
      "source": [
        "* P(w|label) = (count(w|label)+1) /(count(c)+|V|) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV0-9O_ap7_w",
        "colab_type": "text"
      },
      "source": [
        "         * count(w/label): số lượng w có trong văn bản thuộc label tương ứng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzeVH04mq2Bx",
        "colab_type": "text"
      },
      "source": [
        "         * count(c): tổng số lượng word trong văn bản thuộc label tương ứng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4LVSJNXrc33",
        "colab_type": "text"
      },
      "source": [
        "         *|V|: số lượng từ khác nhau trên label tương ứng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmxnevMurzjf",
        "colab_type": "text"
      },
      "source": [
        "          * +1 ở đây để tránh trường hợp khi predict một title mà có từ chưa có trong tập training sẽ dẫn đến xác suất có điều kiện của cả câu sẽ bằng 0 => gây sai lệch tròn dự đoán"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XodNsSe4fm_R",
        "colab_type": "text"
      },
      "source": [
        "Đánh giá hiệu suất model bằng accuracy_score: là thương của tổng số lượng các mẫu được dự đoán chính xác với số lượng mẫu dự đoán \n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxLu_YHWrmwD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22xSa4ImhBlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4b78b7c1-f99b-42da-995f-b1dc42b70d7e"
      },
      "source": [
        "y_model=model.predict(X_validation)\n",
        "print(accuracy_score(y_validation,y_model)) "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.895806976323875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKxVnr6chu3f",
        "colab_type": "text"
      },
      "source": [
        "Với model này thì ta thấy được có khoảng 89% nhãn được dự đoán đúng. Dù hiệu suất chưa cao nhưng không đến nỗi tệ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXSNcPWsXmw",
        "colab_type": "text"
      },
      "source": [
        "**Fine Turning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6TO-G37R9dl",
        "colab_type": "text"
      },
      "source": [
        "Sử dụng Grid Search từ thư viện sklearn: đánh giá hiệu suất model dựa trên các hyperparameter được cung cấp để chọn ra các hyperparameter mà làm cho model đạt hiệu suất cao nhất có thể\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ubWQ0ISR_LU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "c8ea92cd-b950-4c64-8ed7-e0747fd74b14"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV  \n",
        "#các hyperparameter cần đánh giá để đưa ra lựa chọn tốt nhất\n",
        "parameters={ 'vect__ngram_range':[(1,1),(1,2),(2,2)], #chọn lựa thuộc tính ngra,_range của hàm CountVectorizer() được xây dựng ở pipeline model, [1,1] đếm theo từ đơn, [1,2] đếm theo từ đơn và theo từng cặp,[2,2] chỉ đếm theo cặp\n",
        "             'tfidf__use_idf': (True,False),  #chọn lựa thuộc tính use_idf của hàm TfidfTransformer(), nếu True thì có thực hiện phương pháp idf giảm giá trị của các từ gây nhiễu, False thì ngược lại     \n",
        "             'clf__alpha':(1e-2,1e-3,1), #Laplace smoothing: tham số được thêm vào lúc tính xác suất có điều kiện ở tử số để tránh trường hợp nếu từ đó không có trong bag of words thì gây ra sai lệch\n",
        "           }\n",
        "gs_clf=GridSearchCV(model,parameters,n_jobs=-1m) \n",
        "#GridSearch trên estimator=model,tham số grid là danh sách các tham số parameters ở trên \n",
        "#n_job=-1 => Sử dụng tất cả CPU để xử lý => Tăng tốc độ xử lý, xử lý\n",
        "gs_clf.fit(X_train,y_train)  # tiến hành fit trên training dataset để tìm ra tham số tốt nhất cho model"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vect',\n",
              "                                        CountVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        preprocessor=None,\n",
              "                                                        stop_words=None,\n",
              "                                                        strip_accents=None,\n",
              "                                                        token_pattern='(...\n",
              "                                                         smooth_idf=True,\n",
              "                                                         sublinear_tf=False,\n",
              "                                                         use_idf=True)),\n",
              "                                       ('clf',\n",
              "                                        MultinomialNB(alpha=1.0,\n",
              "                                                      class_prior=None,\n",
              "                                                      fit_prior=True))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__alpha': (0.01, 0.001, 1),\n",
              "                         'tfidf__use_idf': (True, False),\n",
              "                         'vect__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBYlXeKs8cU7",
        "colab_type": "text"
      },
      "source": [
        ".best_params => xem tham số nào được chọn để model đạt hiệu suất tốt nhất"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tUoIQNf8Ppn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3464da14-b629-4b2e-c87f-4d6ae8ef8a70"
      },
      "source": [
        "gs_clf.best_params_"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__alpha': 1, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEGbJ6pcHdBF",
        "colab_type": "text"
      },
      "source": [
        "Với kết quả trên ta thấy laplace smoothing được lựa chọn bằng 1, có sử dụng idf và xây dựng bag of words dựa trên đếm cả từ đơn và từ đôi là đạt accuracy cao nhất"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIHf1XqX9TFS",
        "colab_type": "text"
      },
      "source": [
        "Train lại model với tham số mới: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "910h7JvGIqdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "83a9034b-18f2-4290-cd4f-fe67947dad2f"
      },
      "source": [
        "hyper_model=Pipeline([('vect',CountVectorizer(ngram_range=(1,2))),     #stop_word='english' => loại bỏ các từ thuộc stop_word trong tiếng Anh ( the,on,a,an,...) \n",
        "               ('tfidf',TfidfTransformer(use_idf=True)),\n",
        "               ('clf',MultinomialNB(alpha=1.0)),\n",
        "])\n",
        "hyper_model.fit(X_train,y_train)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 2), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m9hp1RWJCdi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "389c6d43-947a-43b3-baa9-b8aee2e78a5c"
      },
      "source": [
        "new_y_model=hyper_model.predict(X_validation)\n",
        "print(\"Old model accuracy: \",accuracy_score(y_validation,y_model))\n",
        "print(\"New model accuracy: \",accuracy_score(y_validation,new_y_model))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old model accuracy:  0.895806976323875\n",
            "New model accuracy:  0.9348454726188324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGeH7zwQJv4U",
        "colab_type": "text"
      },
      "source": [
        "Ta thấy được sự cải thiện rõ rệt sau khi Fine Tuning: tỉ lệ dự đoán chính xác tăng 4%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOxPcAN2J_TI",
        "colab_type": "text"
      },
      "source": [
        "Cách sử dụng model đã train: Gọi hàm predict_category với tham số truyền vào là một câu nói bất kỳ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Ye4qyt6fi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_category(s,train=X_train,model=hyper_model):\n",
        "   p=[s]                             #vì một câu sẽ là một vector nên ta phải chuyển dạng chuỗi thành vector\n",
        "   pred = model.predict(p)           #tiến hành dự đoán\n",
        "   #giá trị trả về sẽ là 0 hoặc 1, 1 là is_sarcasm, 0 là non_sarcasm\n",
        "   if (pred==1): print(\"is_sacarsm\")  \n",
        "   else: print(\"non_sarcasm\")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6sHasESLEEc",
        "colab_type": "text"
      },
      "source": [
        "VD:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxeOnu5-kbFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e593e7b0-29ef-4ea8-b7f9-54424afbce62"
      },
      "source": [
        "predict_category(\"11 Simple Cocktail Recipes To Try While Quarantining\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "non_sarcasm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHNiptsdLg7P",
        "colab_type": "text"
      },
      "source": [
        "Đối chiếu performance trên 2000 Headlines mới"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiAS55k1Lnxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2079248c-f1bf-454d-f9a0-bc9792c5ab1b"
      },
      "source": [
        "X_new=collected_data['headline'].str.replace('\\d+', '')\n",
        "newheadline_y_model=hyper_model.predict(X_new)\n",
        "accuracy_score(collected_data['is_sarcastic'],newheadline_y_model)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7161100196463654"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS_JbR4AMcJZ",
        "colab_type": "text"
      },
      "source": [
        "Hiệu suất sụt giảm nghiêm trọng so với bộ dữ liệu cũ vì có những tin tức mới hay nhiều word mới có giá trị lớn liên quan đến bài toán không có trong bag of words => sai lệch => giảm hiệu suất"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfSOVlYoMqNu",
        "colab_type": "text"
      },
      "source": [
        "Nhận xét về nhóm bài toán này: Đây là bài toán khó, không thể đạt độ chính xác cao nếu chỉ sử dụng machine learning vì tin tức mỗi ngày mỗi khác, mỗi đổi mới nếu không cập nhật các tin tức mà chỉ sử dụng các bag of words cũ đã được thu thập từ trước thì sẽ thiếu hụt các từ có giá trị cao(weight). Giải pháp: nên sử dụng deep reinforcement learning để giải quyết bài toán này "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAGo0wLQPBQA",
        "colab_type": "text"
      },
      "source": [
        "Thành viên nhóm: 18520017 Lê Phước Đạt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qlpot4wQene",
        "colab_type": "text"
      },
      "source": [
        "Link bộ dữ liệu gốc và tự thu thập: https://drive.google.com/drive/u/0/folders/1sIGYDYuKDfSrkSF9VvVg-EIoy0rdqqsB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chX_V3HpQkmQ",
        "colab_type": "text"
      },
      "source": [
        "Link code mẫu: https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
      ]
    }
  ]
}