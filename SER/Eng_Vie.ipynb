{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eng-Vie.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1rBwuus1sPDM4SlvE7Uyw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lephuocdat2000/-CS114.K21-/blob/master/SER/Eng_Vie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJxquPQ5SJJg",
        "outputId": "d88a97f3-c33c-4ac5-d1ca-761393fc8fb4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-c1x2YQSoVD"
      },
      "source": [
        "import scipy.io.wavfile\n",
        "import numpy as np\n",
        "import sys\n",
        "import glob \n",
        "import librosa\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "from IPython.display import Audio\n",
        "### Time Distributed ConvNet imports ###\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import Image\n",
        "from glob import glob\n",
        "import pickle\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "### Audioimport ###\n",
        "import IPython\n",
        "\n",
        "### Warning ###\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skUWw4-LSuAq"
      },
      "source": [
        "#Download dataset from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdANyxx1SykC"
      },
      "source": [
        "!pip install opendatasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vukakk8So9n"
      },
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV1mTsU0S3mO"
      },
      "source": [
        "#Extract signals and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoBLWFlaS9pu"
      },
      "source": [
        "sample_rate = 16000     \n",
        "max_pad_len = 49100\n",
        "eng_signals = []\n",
        "eng_labels = []\n",
        "dataset_path = '/content/drive/MyDrive/Nhận dạng/ravdess-emotional-speech-audio'\n",
        "actors = os.listdir(dataset_path)\n",
        "\n",
        "for actor_file in actors:\n",
        "    actor_path = os.path.join(dataset_path,actor_file)\n",
        "    filenames = os.listdir(actor_path)\n",
        "    for name in filenames:\n",
        "        temp = int(name[6:8])\n",
        "        if (temp==1) or (temp==3) or (temp==4) or (temp==5):\n",
        "            if temp==1:  eng_labels.append(3)\n",
        "            elif temp==3: eng_labels.append(1)\n",
        "            elif temp==4: eng_labels.append(2)\n",
        "            else: eng_labels.append(0)\n",
        "            file_path = os.path.join(actor_path,name)\n",
        "            y,sr = librosa.load(file_path, sr=sample_rate)\n",
        "            y = zscore(y)\n",
        "            if len(y) < max_pad_len:    \n",
        "                y_padded = np.zeros(max_pad_len)\n",
        "                y_padded[:len(y)] = y\n",
        "                y = y_padded\n",
        "            elif len(y) > max_pad_len:\n",
        "                y = np.asarray(y[:max_pad_len])\n",
        "            eng_signals.append(y)\n",
        "\n",
        "eng_labels = np.array(eng_labels)\n",
        "eng_signals = np.array(eng_signals)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8JO_be7TIi5"
      },
      "source": [
        "#Augment noisy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYm14dhnTJm3",
        "outputId": "76a92a9a-fb30-4e66-cfc0-3040886e5ff3"
      },
      "source": [
        "nb_augmented = 2\n",
        "\n",
        "# Function to add noise to a signals with a desired Signal Noise ratio (SNR)\n",
        "def noisy_signal(signal, snr_low=15, snr_high=30, nb_augmented=2):\n",
        "    \n",
        "    # Signal length\n",
        "    signal_len = len(signal)\n",
        "\n",
        "    # Generate White noise\n",
        "    noise = np.random.normal(size=(nb_augmented, signal_len))\n",
        "    \n",
        "    # Compute signal and noise power\n",
        "    s_power = np.sum((signal / (2.0 ** 15)) ** 2) / signal_len\n",
        "    n_power = np.sum((noise / (2.0 ** 15)) ** 2, axis=1) / signal_len\n",
        "    \n",
        "    # Random SNR: Uniform [15, 30]\n",
        "    snr = np.random.randint(snr_low, snr_high)\n",
        "    \n",
        "    # Compute K coeff for each noise\n",
        "    K = np.sqrt((s_power / n_power) * 10 ** (- snr / 10))\n",
        "    K = np.ones((signal_len, nb_augmented)) * K\n",
        "    \n",
        "    # Generate noisy signal\n",
        "    return signal + K.T * noise\n",
        "\n",
        "print(\"Data Augmentation: START\")\n",
        "eng_augmented_signals = list(map(noisy_signal, eng_signals))\n",
        "print(\"Data Augmentation: END!\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Augmentation: START\n",
            "Data Augmentation: END!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdHOgbvjTMLF"
      },
      "source": [
        "#Extract Mel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bNJShvlTOji",
        "outputId": "0772077d-26e3-49b1-a80c-aa56383ef300"
      },
      "source": [
        "def mel_spectrogram(y, sr=16000, n_fft=512, win_length=256, hop_length=128, window='hamming', n_mels=128, fmax=4000):\n",
        "    \n",
        "    # Compute spectogram\n",
        "    mel_spect = np.abs(librosa.stft(y, n_fft=n_fft, window=window, win_length=win_length, hop_length=hop_length)) ** 2\n",
        "    \n",
        "    # Compute mel spectrogram\n",
        "    mel_spect = librosa.feature.melspectrogram(S=mel_spect, sr=sr, n_mels=n_mels, fmax=fmax)\n",
        "    \n",
        "    # Compute log-mel spectrogram\n",
        "    mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
        "    \n",
        "    return mel_spect\n",
        "\n",
        "\n",
        "# Start feature extraction\n",
        "print(\"Feature extraction: START\")\n",
        "\n",
        "# Compute spectogram for all audio file\n",
        "eng_mel_spects = np.asarray(list(map(mel_spectrogram, eng_signals)))\n",
        "eng_augmented_mel_spects = [np.asarray(list(map(mel_spectrogram, eng_augmented_signals[i]))) for i in range(len(eng_augmented_signals))]\n",
        "\n",
        "# Stop feature extraction\n",
        "print(\"Feature extraction: END!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature extraction: START\n",
            "Feature extraction: END!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHYrS6lnWee9"
      },
      "source": [
        "#Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfsfsF6ZWgVO"
      },
      "source": [
        "Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpk4QwjgWd75"
      },
      "source": [
        "# Build augmented labels and train\n",
        "eng_aug_labels = np.asarray(list(itertools.chain.from_iterable([[label] * nb_augmented for label in eng_labels])))\n",
        "eng_AUG_MEL_SPECTs = np.asarray(list(itertools.chain.from_iterable(eng_augmented_mel_spects)))\n",
        "eng_X_train = np.concatenate((eng_mel_spects,eng_AUG_MEL_SPECTs))\n",
        "eng_y_train = np.concatenate((eng_labels,eng_aug_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeNEyY_lWvcQ"
      },
      "source": [
        "Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcvCzx6vWww_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}